from groq import Groq
import json
import re
import csv
import time
from datetime import datetime
from collections import Counter
from pymongo import MongoClient
from tqdm import tqdm


OLLAMA_URL = "http://localhost:11434/v1"
MODEL_NAME = "qwen2.5-14b"  

# --- USER PROMPTS ---
try:
    SAMPLE_SIZE = int(input("Enter sample size (e.g., 1000): ").strip())
except ValueError:
    SAMPLE_SIZE = 1000
    print("‚ö†Ô∏è Invalid input, defaulting SAMPLE_SIZE to 1000.")

empty_choice = input("Do you want to wipe all AI ratings before regrading? (yes/no): ").strip().lower()
EMPTY_COLLECTION = empty_choice in ["yes", "y", "true", "1"]

print(f"‚úÖ SAMPLE_SIZE set to {SAMPLE_SIZE}")
print(f"‚úÖ EMPTY_COLLECTION set to {EMPTY_COLLECTION}")

# --- CONFIGURATION ---
MONGO_URI = "mongodb://localhost:27017/"
DB_NAME = "vocaba"
COLLECTION_NAME = "english"

# --- SETUP ---
client = Groq(api_key="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")

TRANSLATOR_MODEL = MODEL_NAME
ANALYZER_MODEL = MODEL_NAME

# --- CEFR Mapping ---
CEFR_MAP = {"A1": 1, "A2": 2, "B1": 3, "B2": 4, "C1": 5, "C2": 6}

def translator(english_sentence: str) -> str:
    """Translate English ‚Üí Spanish using llama3."""
    response = client.chat.completions.create(
        model=TRANSLATOR_MODEL,
        messages=[
            {"role": "system", "content": "Translate the following English sentence into natural, fluent Spanish. Output only the Spanish sentence."},
            {"role": "user", "content": english_sentence}
        ],
        max_completion_tokens=100,
        temperature=0.0,
        reasoning_effort="none",
        stream=False
    )
    return response.choices[0].message.content.strip()

def analyzer(spanish_sentence: str, max_retries: int = 10, pause: float = 0.5) -> str:
    """Classify Spanish sentence by CEFR level. Returns 'UNKNOWN' if JSON parsing fails."""
    valid_levels = {"A1","A2","B1","B2","C1","C2"}
     
    for attempt in range(1, max_retries + 1):
        try:
            response = client.chat.completions.create(
            model=ANALYZER_MODEL,
            messages=[
                {"role": "system", "content": (
                    "Classify the following Spanish sentence by CEFR level (A1, A2, B1, B2, C1, C2). "
                    "Guidelines: "
                    "A1 = simple present tense with basic vocabulary. "
                    "A2 = idiomatic expressions (tener hambre, tener fr√≠o), habitual actions, modal verbs (tener que, poder, necesitar, querer), preference verbs (gustar, encantar). "
                    "B1 = past and future tenses, present perfect, everyday reasoning. "
                    "B2 = sentences with connectors (aunque, sin embargo, mientras, cuando) OR multiple independent clauses joined by punctuation (semicolon, colon, dash), and subjunctive in common contexts (es posible que, prefiero que). "
                    "C1 = complex conditionals, nuanced subjunctive, advanced connectors. "
                    "C2 = abstract, academic, or philosophical sentences, even if expressed in simple present tense. "
                    "Classify at the highest CEFR level indicated by the grammar or vocabulary present. "
                    "Sentences containing idioms, connectors, modal verbs, or academic language should not be treated as A1."
                     "Respond ONLY with a JSON object of the form: "
                      "{ \"cefr_level\": \"A1|A2|B1|B2|C1|C2\", \"reasoning\": \"explanation\" } "
                    "The 'cefr_level' MUST be exactly one of: A1, A2, B1, B2, C1, C2."

                )},

                # --- A1 anchors ---
                {"role": "user", "content": "Tengo un gato."}, {"role": "assistant", "content": "A1"},
                {"role": "user", "content": "Ella vive en Madrid."}, {"role": "assistant", "content": "A1"},
                {"role": "user", "content": "Mi casa es peque√±a."}, {"role": "assistant", "content": "A1"},
                {"role": "user", "content": "El libro est√° en la mesa."}, {"role": "assistant", "content": "A1"},
                {"role": "user", "content": "√âl come una manzana."}, {"role": "assistant", "content": "A1"},

                # --- A2 anchors ---
                {"role": "user", "content": "Tengo que limpiar mi habitaci√≥n."}, {"role": "assistant", "content": "A2"},
                {"role": "user", "content": "Tengo hambre despu√©s de correr."}, {"role": "assistant", "content": "A2"},
                {"role": "user", "content": "Tengo fr√≠o en invierno."}, {"role": "assistant", "content": "A2"},
                {"role": "user", "content": "Voy al supermercado cada s√°bado."}, {"role": "assistant", "content": "A2"},
                {"role": "user", "content": "Me gusta bailar salsa."}, {"role": "assistant", "content": "A2"},
                {"role": "user", "content": "¬øPuedes ayudarme con la tarea?"}, {"role": "assistant", "content": "A2"},
                {"role": "user", "content": "Necesito comprar un regalo."}, {"role": "assistant", "content": "A2"},
                {"role": "user", "content": "Quiero aprender a tocar la guitarra."}, {"role": "assistant", "content": "A2"},

                # --- B1 anchors ---
                {"role": "user", "content": "Ayer fui al cine con mis amigos."}, {"role": "assistant", "content": "B1"},
                {"role": "user", "content": "Ma√±ana visitar√© a mis abuelos."}, {"role": "assistant", "content": "B1"},
                {"role": "user", "content": "He terminado mi tarea."}, {"role": "assistant", "content": "B1"},
                {"role": "user", "content": "Este es el pueblo del que te habl√©."}, {"role": "assistant", "content": "B1"},
                {"role": "user", "content": "Com√≠ caviar por primera vez."}, {"role": "assistant", "content": "B1"},

                # --- B2 anchors ---
                {"role": "user", "content": "Aunque estaba cansado, termin√© el proyecto."}, {"role": "assistant", "content": "B2"},
                {"role": "user", "content": "Prefiero que vengas temprano."}, {"role": "assistant", "content": "B2"},
                {"role": "user", "content": "Es posible que llueva ma√±ana."}, {"role": "assistant", "content": "B2"},
                {"role": "user", "content": "Sin embargo, decidimos continuar."}, {"role": "assistant", "content": "B2"},
                {"role": "user", "content": "Cuando termine el curso, buscar√© trabajo."}, {"role": "assistant", "content": "B2"},
                {"role": "user", "content": "No abras antes de que el tren se detenga."}, {"role": "assistant", "content": "B2"},

                # --- New idiomatic/discourse anchors ---
                {"role": "user", "content": "No te puedes perder; est√° justo en el centro."}, {"role": "assistant", "content": "B2"},
                {"role": "user", "content": "Es f√°cil encontrarlo; hay se√±ales por todas partes."}, {"role": "assistant", "content": "B2"},
                {"role": "user", "content": "No cabe duda; la ciudad ofrece muchas oportunidades."}, {"role": "assistant", "content": "B2"},
                {"role": "user", "content": "Lo m√°s probable es que llegues a tiempo; el tren suele ser puntual."}, {"role": "assistant", "content": "B2"},
                {"role": "user", "content": "No te preocupes; siempre hay alguien dispuesto a ayudar."}, {"role": "assistant", "content": "B2"},

                # --- C2 anchors ---
                {"role": "user", "content": "La epistemolog√≠a cuestiona los fundamentos del conocimiento humano."}, {"role": "assistant", "content": "C2"},
                {"role": "user", "content": "La literatura posmoderna refleja la fragmentaci√≥n de la identidad contempor√°nea."}, {"role": "assistant", "content": "C2"},
                {"role": "user", "content": "La ontolog√≠a estudia la naturaleza del ser y la existencia."}, {"role": "assistant", "content": "C2"},
                {"role": "user", "content": "La segunda mitad de la vida de un hombre est√° compuesta √∫nicamente por los h√°bitos que ha adquirido durante la primera mitad."}, {"role": "assistant", "content": "C2"},
                {"role": "user", "content": "Estoy en contra de usar la muerte como castigo. Tambi√©n estoy en contra de usarla como recompensa."}, {"role": "assistant", "content": "C2"},

                # --- New academic/abstract anchors ---
                {"role": "user", "content": "Las personas ciegas a veces desarrollan una habilidad compensatoria para percibir la proximidad de los objetos que las rodean."}, {"role": "assistant", "content": "C2"},
                {"role": "user", "content": "La neurociencia analiza c√≥mo el cerebro procesa est√≠mulos externos."}, {"role": "assistant", "content": "C2"},
                {"role": "user", "content": "La √©tica examina las normas que regulan la conducta humana."}, {"role": "assistant", "content": "C2"},
                {"role": "user", "content": "La sociolog√≠a estudia las estructuras y din√°micas de las sociedades modernas."}, {"role": "assistant", "content": "C2"},
                {"role": "user", "content": "La filosof√≠a pol√≠tica reflexiona sobre la legitimidad del poder y la justicia social."}, {"role": "assistant", "content": "C2"},
                    
                # --- Actual request ---
                {"role": "user", "content": spanish_sentence},
            ],
            response_format={ "type": "json_object" },
            temperature=0.0,
            top_p=1.0,
            reasoning_effort="default",
            stream=False,
            max_completion_tokens=1000,
        )

            raw_output = response.choices[0].message.content.strip()
            data = json.loads(raw_output)
            
            cefr_level = data.get("cefr_level", "UNKNOWN").strip()
            reasoning = data.get("reasoning", "").strip()
            
            # --- Strict validation ---
            if cefr_level not in valid_levels:
                print(f"‚ö†Ô∏è Invalid CEFR level: {cefr_level} ‚Üí forcing UNKNOWN")
                cefr_level = "UNKNOWN"

            print(f"‚úÖ CEFR level: {cefr_level}")
            return cefr_level, reasoning

        except Exception as e:
                print(f"‚ö†Ô∏è Attempt {attempt} failed on: {spanish_sentence} ‚Üí {e}")
                if attempt < max_retries:
                    time.sleep(pause)
                    continue
                return "UNKNOWN"

def package_result(english_sentence: str) -> dict:
    spanish = translator(english_sentence)
    cefr = analyzer(spanish)
    cefr_val = CEFR_MAP.get(cefr, 0)
    return {"translation": spanish, "cefr_level": cefr, "cefr_value": cefr_val}

def reset_ai_ratings(collection):
    confirm = input("‚ö†Ô∏è Are you sure you want to wipe ALL AI ratings (yes/no)? ").strip().lower()
    if confirm not in ["yes", "y"]:
        print("‚ùå Reset cancelled.")
        return
    print("‚ö†Ô∏è Resetting all AI-generated fields...")
    result = collection.update_many({}, {"$unset": {
        "translation": "", "cefr_level": "", "cefr_value": "", "ai_model": "", "updated_at": ""
    }})
    print(f"‚úÖ Reset complete. Removed AI ratings from {result.modified_count} documents.")

def report_results(collection, query=None):
    if query is None:
        query = {"cefr_level": {"$exists": True}}
    cursor = collection.find(query, {"cefr_level": 1, "translation": 1})
    levels = [doc.get("cefr_level", "UNKNOWN") for doc in cursor]
    counts = Counter(levels)
    print("\nüìä CEFR Classification Report")
    for level in ["A1", "A2", "B1", "B2", "C1", "C2", "UNKNOWN"]:
        print(f"{level}: {counts.get(level, 0)}")
    total = sum(counts.values())
    print(f"\nTotal classified sentences: {total}")
    if counts.get("UNKNOWN", 0) > 0:
        print("‚ö†Ô∏è Some sentences were marked UNKNOWN ‚Äî review raw outputs for drift.")

def test_harness(export_csv=False, csv_path="harness_results.csv"):
    test_cases = [
        ("Tengo un gato.", "A1"), 
        ("Ella vive en Madrid.", "A1"),
        ("Comemos pan.", "A1"),
        ("Mi hermano trabaja en una oficina.", "A1"),
        ("Los ni√±os juegan en el parque.", "A1"),
        ("Estudio espa√±ol todos los d√≠as.", "A1"),
        ("Bebo agua.", "A1"),
        ("Ellos leen un libro.", "A1"),
        ("Nosotros cantamos una canci√≥n.", "A1"),
        ("El perro corre r√°pido.", "A1"),

        # --- A2: idioms, modal, reversal verbs ---
        ("Tengo que limpiar mi habitaci√≥n.", "A2"),
        ("Me gusta bailar salsa.", "A2"),
        ("Tengo fr√≠o en invierno.", "A2"),
        ("Nos encanta viajar en verano.", "A2"),
        ("¬øPuedes ayudarme con la tarea?", "A2"),
        ("Voy al supermercado cada s√°bado.", "A2"),
        ("Necesito comprar un regalo.", "A2"),
        ("Quiero aprender a tocar la guitarra.", "A2"),
        ("Me duele la cabeza.", "A2"),
        ("Prefiero comer pizza.", "A2"),

        # --- B1: past/future ---
        ("Ayer fui al cine con mis amigos.", "B1"),
        ("Ma√±ana visitar√© a mis abuelos.", "B1"),
        ("Estudi√© mucho para el examen.", "B1"),
        ("Comprar√© un coche el pr√≥ximo a√±o.", "B1"),
        ("Si estudio m√°s, aprobar√© el curso.", "B1"),
        ("El verano pasado viajamos a Italia.", "B1"),
        ("Cuando era ni√±o, jugaba al f√∫tbol.", "B1"),
        ("El mes que viene empezar√© un nuevo trabajo.", "B1"),
        ("He terminado mi tarea.", "B1"),
        ("Si llueve, no iremos al parque.", "B1"),

        # --- B2: connectors, subjunctive ---
        ("Aunque estaba cansado, termin√© el proyecto.", "B2"),
        ("Prefiero que vengas temprano.", "B2"),
        ("Sin embargo, decidimos continuar.", "B2"),
        ("Mientras trabajaba, escuchaba m√∫sica.", "B2"),
        ("Es posible que llueva ma√±ana.", "B2"),
        ("Quiero que me expliques la situaci√≥n.", "B2"),
        ("Aunque no me gusta, lo har√©.", "B2"),
        ("Es mejor que estudies ahora.", "B2"),
        ("No creo que sea verdad.", "B2"),
        ("Cuando termine el curso, buscar√© trabajo.", "B2"),

        # --- C1: complex conditionals, nuanced ---
        ("Si hubiera tenido m√°s tiempo, habr√≠a viajado a Italia.", "C1"),
        ("Es probable que hubiera ocurrido de otra manera.", "C1"),
        ("De haberlo sabido, habr√≠a actuado distinto.", "C1"),
        ("Aunque me lo hubieras pedido, no habr√≠a aceptado.", "C1"),
        ("El hecho de que lo hiciera demuestra su compromiso.", "C1"),
        ("Si hubieras estudiado m√°s, habr√≠as aprobado f√°cilmente.", "C1"),
        ("Es posible que hubiera sido diferente si lo intentaras.", "C1"),

        # --- C2: abstract, academic ---
        ("La globalizaci√≥n ha generado una interdependencia econ√≥mica sin precedentes.", "C2"),
        ("La epistemolog√≠a cuestiona los fundamentos del conocimiento humano.", "C2"),
        ("El paradigma cient√≠fico se transform√≥ radicalmente tras la revoluci√≥n cu√°ntica.", "C2"),
        ("La literatura posmoderna refleja la fragmentaci√≥n de la identidad contempor√°nea.", "C2"),
        ("La semi√≥tica analiza los signos y su interpretaci√≥n cultural.", "C2"),
        ("La hermen√©utica explora la interpretaci√≥n de los textos en contextos hist√≥ricos.", "C2"),
        ("La ontolog√≠a estudia la naturaleza del ser y la existencia.", "C2"),
    ]


    print("\nüî¨ Running CEFR Test Harness...\n")
    correct, incorrect = 0, 0
    results = []

    for sentence, expected in test_cases:
        predicted = analyzer(sentence)
        is_correct = (predicted == expected)
        if is_correct:
            correct += 1
        else:
            incorrect += 1

        results.append({"sentence": sentence, "expected": expected, "predicted": predicted, "correct": is_correct})
        print(f"Sentence: {sentence}")
        print(f"Classification: {predicted} | Expected: {expected} | {'‚úÖ Correct' if is_correct else '‚ùå Incorrect'}\n")

    total = correct + incorrect
    accuracy = (correct / total * 100) if total > 0 else 0

    print("üìä Test Harness Summary")
    print(f"Total cases: {total}")
    print(f"Correct: {correct}")
    print(f"Incorrect: {incorrect}")
    print(f"Accuracy: {accuracy:.1f}%\n")
    
    drift_report(results)

    if export_csv:
        with open(csv_path, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=["sentence", "expected", "predicted", "correct"])
            writer.writeheader()
            writer.writerows(results)


def drift_report(results):
    """
    Compare predicted vs expected CEFR levels and flag drift.
    Drift = predicted one level lower or higher than expected.
    Also computes drift percentage.
    """
    drift_cases = []
    total = len(results)

    for item in results:
        sentence = item["sentence"]
        expected = item["expected"]
        predicted = item["predicted"]

        if expected in CEFR_MAP and predicted in CEFR_MAP:
            diff = CEFR_MAP[predicted] - CEFR_MAP[expected]
            if abs(diff) == 1:  # one-level drift
                drift_cases.append((sentence, expected, predicted))

    print("\n‚ö†Ô∏è Drift Report")
    if drift_cases:
        for s, e, p in drift_cases:
            print(f"Sentence: {s} | Expected: {e} | Predicted: {p}")
        drift_pct = (len(drift_cases) / total * 100) if total > 0 else 0
        print(f"\nTotal drift cases: {len(drift_cases)}")
        print(f"Drift percentage: {drift_pct:.1f}%")
    else:
        print("No drift detected ‚úÖ")


# --- Main Workflow ---
def main():
    mongo_client = MongoClient(MONGO_URI)
    collection = mongo_client[DB_NAME][COLLECTION_NAME]

    if EMPTY_COLLECTION:
        reset_ai_ratings(collection)
        
        
    # Query only for documents that lack a CEFR analysis
    query = {"cefr_level": {"$exists": False}, "text": {"$exists": True}}
    
    # Get total count of documents matching the query (for tqdm total)
    total_to_process = collection.count_documents(query)
    limit = min(total_to_process, SAMPLE_SIZE)
    
    print(f"Starting analysis of {limit} unrated sentences using {TRANSLATOR_MODEL} + {ANALYZER_MODEL}...")

    # Fetch documents based on the calculated limit
    cursor = collection.find(query, {"_id": 1, "text": 1}).limit(limit)

    for doc in tqdm(cursor, total=limit, desc="Processing sentences"):
        try:
            sentence = doc["text"]
            result = package_result(sentence)

            collection.update_one(
                {"_id": doc["_id"]},
                {"$set": {
                    "translation": result["translation"],
                    "cefr_level": result["cefr_level"],
                    "cefr_value": result["cefr_value"],
                    "ai_model": ANALYZER_MODEL,
                    "updated_at": datetime.utcnow()
                }}
            )
        except Exception as e:
            print(f"\n‚ùå Error processing ID {doc['_id']}: {e}")
            
    print("‚úÖ Processing complete.")
    report_results(collection)

# --- Entrypoint ---
if __name__ == "__main__":
    # Run harness first to validate tricky cases
    test_harness(export_csv=True)

    # Then run full pipeline if satisfied
    main()
    